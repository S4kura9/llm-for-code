# llm-for-code
## Collection on Large Language Models for Code Generation


## Development of LLM
| Name|Date                                         |Link                                     |
|----------------------|--------------------------------|-------------------------------------------------|
|Transformer|2017.6|[Attention is all you need](https://arxiv.org/abs/1706.03762)|
|GPT|2018.6|[Improving Language Understanding by Generative Pre-Training](https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035)|
|BERT|2018.10|[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) |
|GPT-2|2019.2| |
|GPT-3|2020.5| |


## Something to be done
| Name|Date                                         |Link                                     |
|----------------------|--------------------------------|-------------------------------------------------|
||||

